# üéØ Melhorias do Modelo para Reduzir RMSE

## An√°lise do Modelo Atual

### Features Atuais Utilizadas:
1. **B√°sicas:** `preco_num`, `media_temporada`, `media_3_rodadas`, `posicao_id`
2. **Contextuais:** `fl_mandante`, `adv_media_gols_feitos`, `adv_media_gols_sofridos`
3. **Scouts:** M√©dias de scouts individuais (G, A, DS, SG, etc.) - `media_{scout}_last3` e `media_{scout}_season`
4. **B√¥nus P√≥s-Predi√ß√£o:** Aplicado via `aplicar_bonus_tatico()` usando odds e for√ßa do advers√°rio

### Pontos Fortes:
- ‚úÖ Modelos especializados por posi√ß√£o (gol, def, mei, ata, tec)
- ‚úÖ Uso de EMA (Exponential Moving Average) para capturar momentum
- ‚úÖ Features de scouts individuais
- ‚úÖ Considera√ß√£o de mando de campo e for√ßa do advers√°rio

### Pontos Fracos Identificados:
- ‚ùå Features de contexto do jogo limitadas
- ‚ùå Falta de features de tend√™ncia (acelera√ß√£o, n√£o s√≥ velocidade)
- ‚ùå Tratamento de outliers/extremos pode ser melhorado
- ‚ùå Features de intera√ß√£o limitadas
- ‚ùå N√£o considera contexto temporal (fase do campeonato, import√¢ncia do jogo)
- ‚ùå N√£o usa hist√≥rico head-to-head
- ‚ùå Features de consist√™ncia vs explosividade n√£o exploradas
- ‚ùå Uso limitado das odds (s√≥ probabilidade de vit√≥ria)

---

## üöÄ Melhorias por Impacto Esperado no RMSE

### üî¥ **IMPACTO MUITO ALTO** (Redu√ß√£o esperada: 10-20% no RMSE)

#### 1. **Features de Tend√™ncia e Acelera√ß√£o (Momentum Avan√ßado)**
**Problema:** O modelo usa apenas m√©dia m√≥vel, mas n√£o captura se o jogador est√° melhorando ou piorando.

**Solu√ß√£o:**
```python
# Adicionar em preparar_features_historicas()

# 1. Tend√™ncia (Slope) - Se est√° subindo ou descendo
df['pontos_tendencia'] = df.groupby(['ano', 'atleta_id'])['pontos_last'].transform(
    lambda x: x.rolling(window=5, min_periods=3).apply(
        lambda y: np.polyfit(range(len(y)), y, 1)[0] if len(y) >= 2 else 0
    )
)

# 2. Acelera√ß√£o (Mudan√ßa na tend√™ncia)
df['pontos_aceleracao'] = df.groupby(['ano', 'atleta_id'])['pontos_tendencia'].diff()

# 3. Volatilidade Recente vs Hist√≥rica (Consist√™ncia)
df['volatilidade_recente'] = df.groupby(['ano', 'atleta_id'])['pontos_last'].transform(
    lambda x: x.rolling(window=5, min_periods=3).std()
)
df['volatilidade_historica'] = df.groupby(['ano', 'atleta_id'])['pontos_last'].transform(
    lambda x: x.expanding().std()
)
df['ratio_volatilidade'] = df['volatilidade_recente'] / (df['volatilidade_historica'] + 0.1)

# 4. Sequ√™ncia de Jogos (Momentum de Confian√ßa)
df['sequencia_positiva'] = df.groupby(['ano', 'atleta_id'])['pontos_last'].transform(
    lambda x: (x >= x.rolling(window=10, min_periods=1).mean()).rolling(window=3).sum()
)
```

**Impacto:** Captura fases de jogadores (em alta/em baixa) que a m√©dia simples perde.

---

#### 2. **Features de Contexto do Jogo e Fase do Campeonato**
**Problema:** Jogos t√™m import√¢ncias diferentes (in√≠cio, meio, fim de campeonato, cl√°ssicos).

**Solu√ß√£o:**
```python
# Adicionar em preparar_features_historicas()

# 1. Fase do Campeonato (Normalizada 0-1)
df['fase_campeonato'] = df['rodada'] / 38.0

# 2. Import√¢ncia do Jogo (Baseado na posi√ß√£o na tabela)
# Precisa calcular posi√ß√£o do time na tabela naquela rodada
def calcular_posicao_tabela(df_partidas, clube_id, ano, rodada):
    # Calcula pontos at√© aquela rodada
    # Retorna posi√ß√£o (1-20)
    pass

df['posicao_tabela'] = df.apply(
    lambda row: calcular_posicao_tabela(df_partidas, row['clube_id_num'], row['ano'], row['rodada']),
    axis=1
)
df['pressao_tabela'] = np.where(df['posicao_tabela'] <= 4, 1.0,  # L√≠deres
                        np.where(df['posicao_tabela'] >= 17, 1.0,  # Zona de rebaixamento
                        0.5))  # Meio da tabela

# 3. Confronto Direto (Head-to-Head)
def calcular_h2h(df_partidas, clube_id, adversario_id, ano, rodada):
    # Hist√≥rico de confrontos entre os dois times
    # Retorna: m√©dia de gols feitos, m√©dia de gols sofridos, aproveitamento
    pass

df['h2h_media_gols'] = df.apply(
    lambda row: calcular_h2h(df_partidas, row['clube_id_num'], row['adversario_id'], row['ano'], row['rodada']),
    axis=1
)

# 4. Sequ√™ncia de Resultados do Time
def calcular_sequencia_time(df_partidas, clube_id, ano, rodada):
    # √öltimos 5 resultados do time (V/E/D)
    # Retorna: sequ√™ncia de vit√≥rias, empates, derrotas
    pass

df['time_sequencia_vitorias'] = df.apply(
    lambda row: calcular_sequencia_time(df_partidas, row['clube_id_num'], row['ano'], row['rodada']),
    axis=1
)
```

**Impacto:** Jogadores em jogos importantes ou em fases cr√≠ticas t√™m comportamento diferente.

---

#### 3. **Features de Intera√ß√£o (Sinergia entre Vari√°veis)**
**Problema:** O modelo n√£o captura intera√ß√µes importantes (ex: mando de campo + for√ßa advers√°rio).

**Solu√ß√£o:**
```python
# Adicionar features de intera√ß√£o

# 1. Mando √ó For√ßa do Advers√°rio
df['mando_x_adv_gols_sofridos'] = df['fl_mandante'] * df['adv_media_gols_sofridos']
df['mando_x_adv_gols_feitos'] = df['fl_mandante'] * df['adv_media_gols_feitos']

# 2. Posi√ß√£o √ó For√ßa do Advers√°rio (Espec√≠fico por posi√ß√£o)
df['ata_x_adv_gols_sofridos'] = (df['posicao_id'] == 5).astype(int) * df['adv_media_gols_sofridos']
df['def_x_adv_gols_feitos'] = (df['posicao_id'].isin([2, 3])).astype(int) * df['adv_media_gols_feitos']

# 3. Momentum √ó Pre√ßo (Jogador em alta e barato = bom neg√≥cio)
df['momentum_x_custo_beneficio'] = df['media_3_rodadas'] / (df['preco_num'] + 0.1)

# 4. Volatilidade √ó M√©dia (Explosivo vs Consistente)
df['volatilidade_x_media'] = df['volatilidade'] * df['media_temporada']

# 5. Tend√™ncia √ó Mando (Jogador em alta jogando em casa)
df['tendencia_x_mando'] = df['pontos_tendencia'] * df['fl_mandante']
```

**Impacto:** Captura rela√ß√µes n√£o-lineares que o XGBoost pode n√£o descobrir sozinho.

---

#### 4. **Melhor Uso das Odds (Features Avan√ßadas)**
**Problema:** Apenas probabilidade de vit√≥ria √© usada, mas odds cont√™m mais informa√ß√£o.

**Solu√ß√£o:**
```python
# Adicionar em preprocessamento ou preparar_features_historicas()

# 1. Valor Esperado da Vit√≥ria (Expected Value)
df['ev_vitoria'] = df['prob_vitoria'] * 3  # 3 pontos por vit√≥ria

# 2. Implied Probability de Over/Under (se dispon√≠vel)
# Odds de Over 2.5 gols indica jogo aberto (bom para atacantes)

# 3. Discrep√¢ncia entre Odds e Estat√≠sticas
df['odds_vs_stats'] = df['prob_vitoria'] - df['aproveitamento_time'] / 100

# 4. Probabilidade de Empate (Importante para defensores)
df['prob_empate'] = (1 / df['odd_empate']) / df['soma_inverso_odds']

# 5. Probabilidade de Gols (Over/Under impl√≠cito)
# Se odd Over 2.5 √© baixa, jogo tende a ter muitos gols
```

**Impacto:** Odds refletem conhecimento coletivo do mercado, s√£o muito informativas.

---

### üü† **IMPACTO ALTO** (Redu√ß√£o esperada: 5-10% no RMSE)

#### 5. **Features de Contexto do Time (N√£o s√≥ do Jogador)**
**Problema:** Jogadores do mesmo time t√™m correla√ß√£o, mas isso n√£o √© explorado.

**Solu√ß√£o:**
```python
# 1. M√©dia de Pontos dos Companheiros de Time (√öltimas 3 rodadas)
df['time_media_pontos'] = df.groupby(['ano', 'rodada', 'clube_id_num'])['pontuacao'].transform('mean')

# 2. For√ßa do Ataque do Time (Para defensores - se time ataca bem, defesa sofre menos)
df['time_forca_ataque'] = df.groupby(['ano', 'rodada', 'clube_id_num']).apply(
    lambda x: x[x['posicao_id'].isin([4, 5])]['pontuacao'].mean()
)

# 3. For√ßa da Defesa do Time (Para atacantes - se defesa √© forte, ataque tem menos press√£o)
df['time_forca_defesa'] = df.groupby(['ano', 'rodada', 'clube_id_num']).apply(
    lambda x: x[x['posicao_id'].isin([1, 2, 3])]['pontuacao'].mean()
)

# 4. Sequ√™ncia de Resultados do Time
df['time_ultimos_5_resultados'] = calcular_sequencia_resultados_time(df, clube_id, ano, rodada)

# 5. Posi√ß√£o na Tabela (J√° mencionado acima, mas importante)
```

**Impacto:** Jogadores de times em boa fase tendem a pontuar mais.

---

#### 6. **Features de Consist√™ncia vs Explosividade**
**Problema:** Modelo n√£o diferencia jogadores consistentes de explosivos.

**Solu√ß√£o:**
```python
# 1. Coeficiente de Varia√ß√£o (CV)
df['cv_pontuacao'] = df['volatilidade_historica'] / (df['media_temporada'] + 0.1)

# 2. Frequ√™ncia de Pontua√ß√µes Altas
df['freq_alta'] = df.groupby(['ano', 'atleta_id'])['pontos_last'].transform(
    lambda x: (x >= x.quantile(0.75)).rolling(window=10, min_periods=5).mean()
)

# 3. Frequ√™ncia de Pontua√ß√µes Baixas
df['freq_baixa'] = df.groupby(['ano', 'atleta_id'])['pontos_last'].transform(
    lambda x: (x <= x.quantile(0.25)).rolling(window=10, min_periods=5).mean()
)

# 4. M√°ximo vs M√©dia (Potencial de Explos√£o)
df['max_vs_media'] = df.groupby(['ano', 'atleta_id'])['pontos_last'].transform(
    lambda x: x.rolling(window=10, min_periods=5).max() / (x.rolling(window=10, min_periods=5).mean() + 0.1)
)

# 5. Percentil Recente (Como est√° em rela√ß√£o ao pr√≥prio hist√≥rico)
df['percentil_recente'] = df.groupby(['ano', 'atleta_id'])['pontos_last'].transform(
    lambda x: (x.iloc[-1] >= x.rolling(window=20, min_periods=10).quantile(0.5)).astype(int)
)
```

**Impacto:** Ajuda o modelo a diferenciar jogadores "seguros" de "loteria".

---

#### 7. **Tratamento de Outliers e Transforma√ß√µes**
**Problema:** Pontua√ß√µes t√™m distribui√ß√£o assim√©trica (muitos zeros/baixas, poucas altas).

**Solu√ß√£o:**
```python
# 1. Transforma√ß√£o Logar√≠tmica para Features Assim√©tricas
df['log_preco'] = np.log1p(df['preco_num'])
df['log_media'] = np.log1p(df['media_temporada'] + 1)  # +1 para evitar log(0)

# 2. Winsoriza√ß√£o (Limitar extremos)
def winsorize(series, lower=0.05, upper=0.95):
    lower_bound = series.quantile(lower)
    upper_bound = series.quantile(upper)
    return series.clip(lower_bound, upper_bound)

df['media_winsorized'] = df.groupby('posicao_id')['media_temporada'].transform(
    lambda x: winsorize(x)
)

# 3. Binning de Features Cont√≠nuas (Criar categorias)
df['preco_categoria'] = pd.cut(df['preco_num'], bins=[0, 5, 10, 15, 20, 100], labels=['Muito Barato', 'Barato', 'M√©dio', 'Caro', 'Muito Caro'])

# 4. Target Encoding (M√©dia da pontua√ß√£o por categoria)
df['preco_cat_media'] = df.groupby('preco_categoria')['pontuacao'].transform('mean')

# 5. Tratamento Especial para Zeros (Jogadores que n√£o jogaram)
df['jogou'] = (df['pontuacao'] > 0).astype(int)
# Treinar modelo separado para prever se jogou, depois prever pontua√ß√£o condicional
```

**Impacto:** Melhora a capacidade do modelo de lidar com distribui√ß√µes n√£o-normais.

---

#### 8. **Features Temporais Avan√ßadas**
**Problema:** Apenas m√©dia m√≥vel √© usada, mas padr√µes temporais s√£o mais complexos.

**Solu√ß√£o:**
```python
# 1. Sazonalidade (Alguns jogadores s√£o melhores em certas fases)
df['rodada_sin'] = np.sin(2 * np.pi * df['rodada'] / 38)
df['rodada_cos'] = np.cos(2 * np.pi * df['rodada'] / 38)

# 2. Janelas M√∫ltiplas (N√£o s√≥ 3 rodadas)
df['media_1_rodada'] = df.groupby(['ano', 'atleta_id'])['pontos_last'].shift(1)
df['media_5_rodadas'] = df.groupby(['ano', 'atleta_id'])['pontos_last'].transform(
    lambda x: x.rolling(window=5, min_periods=3).mean()
)
df['media_10_rodadas'] = df.groupby(['ano', 'atleta_id'])['pontos_last'].transform(
    lambda x: x.rolling(window=10, min_periods=5).mean()
)

# 3. Diferen√ßa entre Janelas (Momentum de Curto vs Longo Prazo)
df['diff_3_10'] = df['media_3_rodadas'] - df['media_10_rodadas']

# 4. Rec√™ncia Ponderada (√öltimas rodadas t√™m mais peso)
def weighted_average(series, weights):
    return (series * weights).sum() / weights.sum()

df['media_ponderada'] = df.groupby(['ano', 'atleta_id'])['pontos_last'].transform(
    lambda x: x.rolling(window=5, min_periods=3).apply(
        lambda y: weighted_average(y, np.array([5, 4, 3, 2, 1][:len(y)]))
    )
)
```

**Impacto:** Captura padr√µes temporais que m√©dias simples perdem.

---

### üü° **IMPACTO M√âDIO** (Redu√ß√£o esperada: 2-5% no RMSE)

#### 9. **Features de Mercado e Popularidade**
**Problema:** Varia√ß√£o de pre√ßo e popularidade podem indicar expectativa do mercado.

**Solu√ß√£o:**
```python
# 1. Varia√ß√£o de Pre√ßo (Se subiu muito, expectativa alta)
df['variacao_preco_pct'] = df['variacao_num'] / (df['preco_num'] - df['variacao_num'] + 0.1)

# 2. Popularidade (Percentual de times que t√™m o jogador - se dispon√≠vel na API)
# df['popularidade'] = df['escalacoes'] / df['total_times']  # Se dispon√≠vel

# 3. Pre√ßo Relativo √† M√©dia da Posi√ß√£o
df['preco_vs_media_posicao'] = df['preco_num'] / df.groupby('posicao_id')['preco_num'].transform('mean')

# 4. Custo-Benef√≠cio Relativo
df['cb_vs_media_posicao'] = df['custo_beneficio'] / df.groupby('posicao_id')['custo_beneficio'].transform('mean')
```

**Impacto:** Mercado tem informa√ß√£o agregada que pode ser √∫til.

---

#### 10. **Features de Calend√°rio e Descanso**
**Problema:** Jogadores com mais descanso ou sequ√™ncia de jogos podem ter performance diferente.

**Solu√ß√£o:**
```python
# 1. Dias de Descanso (Se dispon√≠vel nos dados)
def calcular_dias_descanso(df_partidas, clube_id, rodada, ano):
    # Calcula dias entre jogos
    pass

df['dias_descanso'] = df.apply(
    lambda row: calcular_dias_descanso(df_partidas, row['clube_id_num'], row['rodada'], row['ano']),
    axis=1
)

# 2. Sequ√™ncia de Jogos (Jogos consecutivos)
df['jogos_consecutivos'] = calcular_sequencia_jogos(df_partidas, clube_id, rodada, ano)

# 3. Fadiga Acumulada (Soma de minutos/jogos recentes)
# Se dispon√≠vel dados de minutos jogados
```

**Impacto:** Fadiga e descanso afetam performance.

---

#### 11. **Ensemble e Calibra√ß√£o de Previs√µes**
**Problema:** Um √∫nico modelo pode ter vi√©s sistem√°tico.

**Solu√ß√£o:**
```python
# 1. Ensemble de Modelos
# Treinar m√∫ltiplos modelos com diferentes:
#   - Hiperpar√¢metros
#   - Features
#   - Janelas temporais
# E fazer m√©dia ponderada

def ensemble_predict(models, X, weights=None):
    if weights is None:
        weights = [1.0 / len(models)] * len(models)
    predictions = [model.predict(X) for model in models]
    return np.average(predictions, axis=0, weights=weights)

# 2. Calibra√ß√£o (Ajustar previs√µes para serem mais calibradas)
from sklearn.calibration import CalibratedRegressorCV
calibrated_model = CalibratedRegressorCV(base_model, cv=5)

# 3. Quantile Regression (Prever intervalos, n√£o s√≥ m√©dia)
from sklearn.ensemble import GradientBoostingRegressor
quantile_models = {
    'q10': GradientBoostingRegressor(loss='quantile', alpha=0.1),
    'q50': GradientBoostingRegressor(loss='quantile', alpha=0.5),
    'q90': GradientBoostingRegressor(loss='quantile', alpha=0.9)
}
```

**Impacto:** Reduz vari√¢ncia e melhora robustez.

---

#### 12. **Feature Selection Inteligente**
**Problema:** Muitas features podem causar overfitting.

**Solu√ß√£o:**
```python
# 1. Mutual Information
from sklearn.feature_selection import mutual_info_regression
mi_scores = mutual_info_regression(X_train, y_train)
selected_features = X_train.columns[mi_scores > threshold]

# 2. Permutation Importance (J√° calculado pelo XGBoost, mas pode ser usado para sele√ß√£o)
# 3. Recursive Feature Elimination
from sklearn.feature_selection import RFE
selector = RFE(XGBRegressor(), n_features_to_select=30)
selector.fit(X_train, y_train)

# 4. Remover Features Altamente Correlacionadas
correlation_matrix = X_train.corr().abs()
upper_triangle = correlation_matrix.where(
    np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)
)
high_corr_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.95)]
```

**Impacto:** Reduz overfitting e melhora generaliza√ß√£o.

---

## üìä Implementa√ß√£o Priorizada

### Fase 1 (Implementar Primeiro - Maior Impacto):
1. ‚úÖ Features de Tend√™ncia e Acelera√ß√£o
2. ‚úÖ Features de Intera√ß√£o
3. ‚úÖ Melhor Uso das Odds
4. ‚úÖ Features de Contexto do Time

### Fase 2 (Segundo):
5. ‚úÖ Features de Consist√™ncia vs Explosividade
6. ‚úÖ Tratamento de Outliers
7. ‚úÖ Features Temporais Avan√ßadas

### Fase 3 (Refinamento):
8. ‚úÖ Features de Contexto do Jogo
9. ‚úÖ Ensemble e Calibra√ß√£o
10. ‚úÖ Feature Selection

---

## üîß Exemplo de C√≥digo Completo

```python
# Adicionar em preparar_features_historicas() ap√≥s linha 247

# ========== FEATURES DE TEND√äNCIA ==========
print("  > Criando features de tend√™ncia...")
df['pontos_tendencia'] = df.groupby(['ano', 'atleta_id'])['pontos_last'].transform(
    lambda x: x.rolling(window=5, min_periods=3).apply(
        lambda y: np.polyfit(range(len(y)), y, 1)[0] if len(y) >= 2 else 0
    )
).fillna(0)

df['pontos_aceleracao'] = df.groupby(['ano', 'atleta_id'])['pontos_tendencia'].diff().fillna(0)

# ========== FEATURES DE INTERA√á√ÉO ==========
print("  > Criando features de intera√ß√£o...")
df['mando_x_adv_gols_sofridos'] = df['fl_mandante'] * df['adv_media_gols_sofridos']
df['mando_x_adv_gols_feitos'] = df['fl_mandante'] * df['adv_media_gols_feitos']
df['ata_x_adv_gols_sofridos'] = (df['posicao_id'] == 5).astype(int) * df['adv_media_gols_sofridos']
df['def_x_adv_gols_feitos'] = (df['posicao_id'].isin([2, 3])).astype(int) * df['adv_media_gols_feitos']

# ========== FEATURES DE CONSIST√äNCIA ==========
print("  > Criando features de consist√™ncia...")
df['volatilidade_recente'] = df.groupby(['ano', 'atleta_id'])['pontos_last'].transform(
    lambda x: x.rolling(window=5, min_periods=3).std()
).fillna(0)

df['volatilidade_historica'] = df.groupby(['ano', 'atleta_id'])['pontos_last'].transform(
    lambda x: x.expanding().std()
).fillna(0)

df['ratio_volatilidade'] = (df['volatilidade_recente'] / (df['volatilidade_historica'] + 0.1)).fillna(1.0)

# ========== FEATURES TEMPORAIS AVAN√áADAS ==========
print("  > Criando features temporais avan√ßadas...")
df['media_5_rodadas'] = df.groupby(['ano', 'atleta_id'])['pontos_last'].transform(
    lambda x: x.rolling(window=5, min_periods=3).mean()
).fillna(df['media_3_rodadas'])

df['media_10_rodadas'] = df.groupby(['ano', 'atleta_id'])['pontos_last'].transform(
    lambda x: x.rolling(window=10, min_periods=5).mean()
).fillna(df['media_temporada'])

df['diff_3_10'] = df['media_3_rodadas'] - df['media_10_rodadas']

# ========== FEATURES DE CONTEXTO DO TIME ==========
print("  > Criando features de contexto do time...")
df['time_media_pontos'] = df.groupby(['ano', 'rodada', 'clube_id_num'])['pontuacao'].transform('mean').fillna(0)

print("  > Features avan√ßadas criadas com sucesso!")
```

---

## üìà M√©tricas para Acompanhar

Ap√≥s implementar cada melhoria, medir:
- **RMSE** (objetivo principal)
- **MAE** (Mean Absolute Error)
- **R¬≤** (Coeficiente de determina√ß√£o)
- **RMSE por Posi√ß√£o** (algumas posi√ß√µes podem melhorar mais)
- **RMSE por Faixa de Pontua√ß√£o** (erro em jogadores de alta pontua√ß√£o vs baixa)

---

## üéØ Expectativa de Redu√ß√£o de RMSE

- **Implementando Fase 1:** Redu√ß√£o de 15-25% no RMSE
- **Implementando Fase 1 + 2:** Redu√ß√£o de 20-30% no RMSE
- **Implementando Tudo:** Redu√ß√£o de 25-35% no RMSE

**Nota:** Resultados podem variar dependendo da qualidade dos dados hist√≥ricos e do RMSE atual.

---

## ‚ö†Ô∏è Cuidados Importantes

1. **Data Leakage:** Garantir que todas as features usem apenas dados dispon√≠veis ANTES da rodada
2. **Overfitting:** Usar valida√ß√£o temporal (n√£o aleat√≥ria) para evitar overfitting
3. **Missing Values:** Tratar adequadamente valores faltantes (n√£o apenas fillna(0))
4. **Feature Scaling:** XGBoost n√£o precisa, mas algumas features podem se beneficiar
5. **Valida√ß√£o Temporal:** Sempre validar em rodadas futuras, n√£o aleat√≥rias

---

## üîÑ Pr√≥ximos Passos

1. Implementar features da Fase 1
2. Retreinar modelos
3. Comparar RMSE antes/depois
4. Iterar e refinar
5. Documentar quais features t√™m maior import√¢ncia (feature importance)

